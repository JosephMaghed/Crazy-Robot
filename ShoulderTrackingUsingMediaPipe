using System.Diagnostics;
using Unity.Barracuda;
using UnityEngine;

public class PoseEstimator : MonoBehaviour
{
    [Header("ONNX Model")]
    public NNModel blazePoseModel;
    private Model runtimeModel;
    private IWorker worker;

    [Header("WebCam")]
    public Renderer planeRenderer;
    private WebCamTexture webcam;
    private Texture2D resizedTex;

    private const int INPUT_SIZE = 256;
    private const int LEFT_SHOULDER_INDEX = 11;
    private const int RIGHT_SHOULDER_INDEX = 12;

    void Start()
    {
        // Load model
        runtimeModel = ModelLoader.Load(blazePoseModel);
        worker = WorkerFactory.CreateWorker(WorkerFactory.Type.Auto, runtimeModel);

        // Start webcam
        webcam = new WebCamTexture();
        webcam.Play();
        planeRenderer.material.mainTexture = webcam;

        // Create reusable resized texture
        resizedTex = new Texture2D(INPUT_SIZE, INPUT_SIZE, TextureFormat.RGB24, false);
    }

    void Update()
    {
        if (webcam.width <= 16) return; // Wait for webcam to init

        // Get frame from webcam
        Color[] pixels = webcam.GetPixels();

        // Resize to 256x256 using Reinitialize (new Unity API)
        resizedTex.Reinitialize(INPUT_SIZE, INPUT_SIZE);
        resizedTex.SetPixels(ScalePixels(pixels, webcam.width, webcam.height, INPUT_SIZE, INPUT_SIZE));
        resizedTex.Apply();

        // Prepare input tensor
        float[,,,] input = new float[1, INPUT_SIZE, INPUT_SIZE, 3];
        Color[] resizedPixels = resizedTex.GetPixels();
        for (int y = 0; y < INPUT_SIZE; y++)
        {
            for (int x = 0; x < INPUT_SIZE; x++)
            {
                Color c = resizedPixels[y * INPUT_SIZE + x];
                input[0, y, x, 0] = c.r * 2f - 1f;
                input[0, y, x, 1] = c.g * 2f - 1f;
                input[0, y, x, 2] = c.b * 2f - 1f;
            }
        }

        // Run inference
        using (var tensor = new Tensor(1, INPUT_SIZE, INPUT_SIZE, 3, input))
        {
            worker.Execute(tensor);
            Tensor output = worker.PeekOutput("Identity_4"); // [1,117] keypoints
            float[] data = output.ToReadOnlyArray();

            // Left & Right Shoulder coords
            float lx = data[LEFT_SHOULDER_INDEX * 3];
            float ly = data[LEFT_SHOULDER_INDEX * 3 + 1];
            float rx = data[RIGHT_SHOULDER_INDEX * 3];
            float ry = data[RIGHT_SHOULDER_INDEX * 3 + 1];

            UnityEngine.Debug.Log($"Left Shoulder (normalized): x={lx:F3}, y={ly:F3}");
            UnityEngine.Debug.Log($"Right Shoulder (normalized): x={rx:F3}, y={ry:F3}");

            output.Dispose();
        }
    }

    private void OnDestroy()
    {
        worker?.Dispose();
        webcam?.Stop();
    }

    // Helper: naive pixel scaling
    private Color[] ScalePixels(Color[] src, int srcW, int srcH, int dstW, int dstH)
    {
        Color[] dst = new Color[dstW * dstH];
        float xRatio = (float)srcW / dstW;
        float yRatio = (float)srcH / dstH;

        for (int y = 0; y < dstH; y++)
        {
            for (int x = 0; x < dstW; x++)
            {
                int srcX = Mathf.FloorToInt(x * xRatio);
                int srcY = Mathf.FloorToInt(y * yRatio);
                dst[y * dstW + x] = src[srcY * srcW + srcX];
            }
        }
        return dst;
    }
}
